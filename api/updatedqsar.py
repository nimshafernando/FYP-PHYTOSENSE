# -*- coding: utf-8 -*-
"""updatedqsar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_E8N9sTzx4mbZAOyDJRll3g4r2cMTb99
"""


from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ================================================================
# DATA TRANSFORMS (augmentation for training, simple for val/test)
# ================================================================
data_transforms = {
    "train": transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    "val": transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    "test": transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

train_dir = "/content/data/train"
val_dir   = "/content/data/val"
test_dir  = "/content/data/test"

image_datasets = {
    "train": datasets.ImageFolder(train_dir, transform=data_transforms["train"]),
    "val": datasets.ImageFolder(val_dir, transform=data_transforms["val"]),
    "test": datasets.ImageFolder(test_dir, transform=data_transforms["test"]),
}

# ================================================================
# DATA LOADERS
# ================================================================
train_loader = DataLoader(image_datasets["train"], batch_size=32, shuffle=True, num_workers=4, pin_memory=True)
val_loader   = DataLoader(image_datasets["val"], batch_size=32, shuffle=False, num_workers=4, pin_memory=True)
test_loader  = DataLoader(image_datasets["test"], batch_size=32, shuffle=False, num_workers=4, pin_memory=True)

# Class names
class_names = image_datasets["train"].classes
print("Number of classes:", len(class_names))
print("Sample classes:", class_names[:10])

import os
from collections import defaultdict

base_dir = "/content/data"
splits = ["train", "val", "test"]

# Dictionary to track counts per class across splits
class_counts = defaultdict(lambda: {"train": 0, "val": 0, "test": 0})

for split in splits:
    folder = os.path.join(base_dir, split)
    for cls in sorted(os.listdir(folder)):
        cls_path = os.path.join(folder, cls)
        if os.path.isdir(cls_path):
            num_images = len([f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))])
            class_counts[cls][split] = num_images

# Print results
for cls, counts in class_counts.items():
    print(f"{cls:20s} | Train: {counts['train']:3d} | Val: {counts['val']:3d} | Test: {counts['test']:3d}")

# Grand totals
total_train = sum(c["train"] for c in class_counts.values())
total_val   = sum(c["val"] for c in class_counts.values())
total_test  = sum(c["test"] for c in class_counts.values())
print("\nTotals -> Train:", total_train, " Val:", total_val, " Test:", total_test, " Overall:", total_train+total_val+total_test)

import os

for split in ["train", "val", "test"]:
    path = f"/content/data/{split}"  # adjust if your split folder is here
    if os.path.exists(path):
        print(split, "->", len(os.listdir(path)), "classes")
        for c in os.listdir(path)[:5]:  # show first 5 classes
            print("   ", c, ":", len(os.listdir(os.path.join(path, c))), "images")
    else:
        print(split, "folder not found!")

import os

# Adjust this path to match your dataset location
train_dir = "/content/data/train"
leaf_classes = sorted(os.listdir(train_dir))
print("ðŸ” Leaf Class Names:")
for cls in leaf_classes:
    print("-", cls)

"""
Enhanced Medicinal Leaf Classification - Three Models with Ensemble
Optimized for Colab Pro with L4 GPU and High-RAM, reduced batch size

SETUP INSTRUCTIONS:
1. Mount Google Drive: drive.mount('/content/drive')
2. Ensure dataset is in Google Drive: /content/drive/MyDrive/medicinal/leaf.zip
3. Select Runtime > Change runtime type > Python 3 > L4 GPU > High-RAM
4. Run this code to resume training from ResNet-50 checkpoint and complete pipeline
"""

# ================================================================
# QUICK SETUP
# ================================================================

from google.colab import drive
try:
    drive.mount('/content/drive')
    print("Google Drive mounted")
except Exception:
    print("Google Drive mounting failed or already mounted")

# Extract dataset to local disk for faster I/O
import zipfile
import os, sys
import shutil

possible_paths = [
    '/content/drive/MyDrive/medicinal/leaf.zip',
    '/content/drive/MyDrive/Medicinal_leaf_dataset.zip',
    '/content/drive/MyDrive/dataset.zip'
]

extracted = False
if not os.path.exists('/content/leaf'):
    for zip_path in possible_paths:
        if os.path.exists(zip_path):
            print(f"Extracting dataset from {zip_path} to /content/leaf...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall('/content/leaf')
            print("Dataset extracted to /content/leaf")
            extracted = True
            break

if os.path.exists('/content/leaf'):
    print("/content/leaf directory found")
elif not extracted:
    print("ZIP file not found. Please place dataset at /content/drive/MyDrive/medicinal/leaf.zip")
    print("Expected structure: /content/leaf/[Plant Species Folders]/[Image Files]")

# Install required packages

# Imports
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets, models
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from collections import Counter
import copy
import time
import json
from glob import glob
from tqdm.auto import tqdm
import warnings
warnings.filterwarnings('ignore')

# Optional: Albumentations bridge
try:
    import albumentations as A
    from albumentations.pytorch import ToTensorV2
    ALB_AVAILABLE = True
except Exception:
    ALB_AVAILABLE = False

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    torch.cuda.empty_cache()

# ================================================================
# CONFIGURATION
# ================================================================

class Config:
    # Data paths
    TRAIN_DIR = "data/train"
    VAL_DIR = "data/val"
    TEST_DIR = "data/test"

    # Training parameters optimized for L4 GPU
    BATCH_SIZE = 32
    NUM_EPOCHS = 50 # Increased epochs
    LEARNING_RATE = 1e-3
    NUM_WORKERS = 4
    DEVICE = device

    # Early stopping
    EARLY_STOPPING_PATIENCE = 5 # Increased patience
    MIN_DELTA = 1e-3

    # Model save paths (local and Google Drive)
    RESNET_PATH = "resnet50_ensemble.pth"
    MOBILENET_PATH = "mobilenetv2_ensemble.pth"
    EFFICIENTNET_PATH = "efficientnet_b0_ensemble.pth"
    DRIVE_RESNET_PATH = "/content/drive/MyDrive/medicinal/resnet50_ensemble.pth"
    DRIVE_MOBILENET_PATH = "/content/drive/MyDrive/medicinal/mobilenetv2_ensemble.pth"
    DRIVE_EFFICIENTNET_PATH = "/content/drive/MyDrive/medicinal/efficientnet_b0_ensemble.pth"
    DRIVE_METADATA_PATH = "/content/drive/MyDrive/medicinal/model_metadata.json"

    # GPU optimizations
    PIN_MEMORY = torch.cuda.is_available()

print("Configuration:")
print(f"  Batch Size: {Config.BATCH_SIZE}")
print(f"  Max Epochs: {Config.NUM_EPOCHS}")
print(f"  Early Stopping Patience: {Config.EARLY_STOPPING_PATIENCE}")
print(f"  Workers: {Config.NUM_WORKERS}")
print(f"  Pin Memory: {Config.PIN_MEMORY}")

# ================================================================
# AUGMENTATION CONFIG (Albumentations adapter + levels)
# ================================================================

class AugmentationConfig:
    LEVELS = {
        "conservative": dict(rotation=15, color=0.2, scale=(0.8, 1.0)),
        "moderate":     dict(rotation=30, color=0.4, scale=(0.7, 1.0)),
        "aggressive":   dict(rotation=45, color=0.6, scale=(0.6, 1.0)),
    }
    def __init__(self, level="moderate"):
        self.set_level(level)
    def set_level(self, level:str):
        level = level.lower()
        if level not in self.LEVELS:
            level = "moderate"
        self.level = level
        self.params = self.LEVELS[level]

class AlbumentationsTransform:
    def __init__(self, aug):
        self.aug = aug
    def __call__(self, img):
        img = np.array(img)
        out = self.aug(image=img)
        return out["image"]

def build_transforms(level="moderate"):
    cfg = AugmentationConfig(level)
    p = cfg.params

    if ALB_AVAILABLE:
        # Explicit sizes everywhere to avoid InitSchema errors
        train_aug = A.Compose([
            A.Resize(height=256, width=256),
            A.RandomResizedCrop(
                height=224,
                width=224,
                size=(224, 224), # Add size explicitly
                scale=p["scale"],
                ratio=(0.8, 1.25),
                p=1.0
            ),
            A.ShiftScaleRotate(
                shift_limit=0.1,
                scale_limit=0.2,
                rotate_limit=p["rotation"],
                border_mode=0,
                value=0,
                p=0.8
            ),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.2 if cfg.level != "conservative" else 0.0),
            A.Perspective(scale=(0.05, 0.1), p=0.2 if cfg.level != "conservative" else 0.0),
            A.ColorJitter(
                brightness=p["color"],
                contrast=p["color"],
                saturation=p["color"],
                hue=min(0.2, p["color"]/2),
                p=0.8
            ),
            A.OneOf([
                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),
                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),
                A.RandomGamma(gamma_limit=(80, 120)),
            ], p=0.4),
            A.OneOf([
                A.GaussianBlur(blur_limit=(3, 5)),
                A.MotionBlur(blur_limit=(3, 3)),  # tuple form
            ], p=0.2 if cfg.level != "conservative" else 0.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

        val_aug = A.Compose([
            A.Resize(height=256, width=256),
            A.CenterCrop(height=224, width=224, size=(224, 224)), # Add size explicitly
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

        train_tf = AlbumentationsTransform(train_aug)
        val_tf = AlbumentationsTransform(val_aug)

    else:
        # Torchvision fallback
        train_tf = transforms.Compose([
            transforms.RandomResizedCrop(size=224, scale=p["scale"]),
            transforms.RandomRotation(degrees=p["rotation"]),
            transforms.ColorJitter(
                brightness=p["color"],
                contrast=p["color"],
                saturation=p["color"],
                hue=min(0.2, p["color"]/2)
            ),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        val_tf = transforms.Compose([
            transforms.Resize(size=256),
            transforms.CenterCrop(size=224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    return train_tf, val_tf

def create_enhanced_transforms():
    """Wrapper around build_transforms to use moderate level augmentation"""
    return build_transforms(level="moderate")

# ================================================================
# DATA SETUP AND PREPARATION
# ================================================================

def setup_dataset():
    """Setup dataset from local /content/leaf structure"""

    if os.path.exists("data/train") and os.path.exists("data/val") and os.path.exists("data/test"):
        print("Data folders already exist, skipping setup")
        return True

    if not os.path.exists('/content/leaf'):
        print("/content/leaf directory not found")
        print("Please ensure dataset is extracted to /content/leaf")
        return False

    print("/content/leaf directory found, proceeding with dataset organization...")

    nested_dirs = [d for d in os.listdir('/content/leaf') if os.path.isdir(os.path.join('/content/leaf', d))]

    if len(nested_dirs) == 1 and not any(f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))
                                        for f in os.listdir(f'/content/leaf/{nested_dirs[0]}')):
        ImagePATH = f"/content/leaf/{nested_dirs[0]}/"
        print(f"Found nested structure: {nested_dirs[0]}")
    else:
        ImagePATH = "/content/leaf/"

    types = glob(ImagePATH + "*")
    types = [t for t in types if os.path.isdir(t)]

    if not types:
        print("No plant folders found")
        try:
            contents = os.listdir(ImagePATH)
            print(contents[:10])
        except Exception:
            print(f"Cannot list {ImagePATH} contents")
        return False

    print(f"Found {len(types)} plant species")
    print(f"Sample species: {[t.split('/')[-1] for t in types[:5]]}")

    filedf = pd.DataFrame()
    total_images = 0

    print("Analyzing image files...")
    for typ in tqdm(types, desc="Scanning folders", unit="folder"):
        files = glob(typ + "/*")
        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]
        if image_files:
            tempdf = pd.DataFrame({'filepath': image_files, 'types': typ.split("/")[-1]})
            filedf = pd.concat([filedf, tempdf])
            total_images += len(image_files)
        else:
            print(f"No image files found in {typ}")

    if len(filedf) == 0:
        print("No image files found in plant folders")
        return False

    print(f"Total images: {total_images}")
    print(f"Unique classes: {len(filedf.types.unique())}")

    class_counts = filedf.types.value_counts()
    print(f"Images per class: {class_counts.min()} - {class_counts.max()}")
    print(f"Average per class: {class_counts.mean():.1f}")

    from sklearn.model_selection import train_test_split

    print("Splitting dataset (60% train, 20% val, 20% test)...")
    try:
        X_train, X_test, Y_train, Y_test = train_test_split(
            filedf, filedf['types'], stratify=filedf['types'], test_size=0.4, random_state=42)
        X_test, X_val, Y_test, Y_val = train_test_split(
            X_test, X_test['types'], stratify=X_test['types'], test_size=0.5, random_state=42)
    except Exception as e:
        print(f"Stratified split failed: {e}")
        X_train, X_test = train_test_split(filedf, test_size=0.4, random_state=42)
        X_test, X_val = train_test_split(X_test, test_size=0.5, random_state=42)

    X_train['use'] = 'train'
    X_val['use'] = 'val'
    X_test['use'] = 'test'

    fulldf = pd.concat([X_train, X_test, X_val])

    print(f"Train: {len(X_train)} images")
    print(f"Validation: {len(X_val)} images")
    print(f"Test: {len(X_test)} images")

    os.makedirs("data", exist_ok=True)
    for split in ['train', 'val', 'test']:
        if os.path.exists(f"data/{split}"):
            shutil.rmtree(f"data/{split}")
        os.makedirs(f"data/{split}", exist_ok=True)

    unique_classes = fulldf.types.unique()
    print(f"Creating folders for {len(unique_classes)} classes...")
    for typ in tqdm(unique_classes, desc="Creating class folders", unit="class"):
        for split in ['train', 'val', 'test']:
            os.makedirs(f"data/{split}/{typ}", exist_ok=True)

    print("Organizing files into train/val/test folders...")
    success_count = 0
    error_count = 0

    for _, row in tqdm(fulldf.iterrows(), total=len(fulldf), desc="Organizing files", unit="file"):
        typ = row['types']
        section = row['use']
        ipath = row['filepath']
        filename = os.path.basename(ipath)
        opath = f"data/{section}/{typ}/{filename}"

        try:
            shutil.copy2(ipath, opath)
            success_count += 1
        except Exception as e:
            error_count += 1
            if error_count < 5:
                print(f"Error copying {ipath}: {e}")

    print("Dataset setup completed")
    print(f"Successfully organized: {success_count} files")
    if error_count > 0:
        print(f"Errors: {error_count} files")

    print("Final verification:")
    for split in ['train', 'val', 'test']:
        split_path = f"data/{split}"
        if os.path.exists(split_path):
            classes = [d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))]
            print(f"  {split}: {len(classes)} classes")

    return True

# ================================================================
# DATA LOADING (with augmentation levels)
# ================================================================

def create_data_loaders(level="moderate"):
    train_tf, val_tf = build_transforms(level)

    print("Loading datasets...")
    train_dataset = datasets.ImageFolder(root=Config.TRAIN_DIR, transform=train_tf)
    val_dataset = datasets.ImageFolder(root=Config.VAL_DIR, transform=val_tf)
    test_dataset = datasets.ImageFolder(root=Config.TEST_DIR, transform=val_tf)

    num_classes = len(train_dataset.classes)
    class_names = train_dataset.classes

    print("Enhanced dataset loaded successfully")
    print(f"Classes: {num_classes}")
    print(f"Train: {len(train_dataset)} images")
    print(f"Val: {len(val_dataset)} images")
    print(f"Test: {len(test_dataset)} images")

    train_loader = DataLoader(
        train_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=True,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY,
        persistent_workers=True if Config.NUM_WORKERS > 0 else False
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY,
        persistent_workers=True if Config.NUM_WORKERS > 0 else False
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY,
        persistent_workers=True if Config.NUM_WORKERS > 0 else False
    )

    return train_loader, val_loader, test_loader, num_classes, class_names

# ================================================================
# MIXUP / CUTMIX (with corrected indexing)
# ================================================================

class MixUpCutMix:
    def __init__(self, mixup_alpha=0.2, cutmix_alpha=1.0, prob=0.5):
        self.mixup_alpha = mixup_alpha
        self.cutmix_alpha = cutmix_alpha
        self.prob = prob

    def mixup_data(self, x, y):
        if np.random.random() > self.prob:
            return x, y, y, 1.0
        batch_size = x.size(0)
        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)
        index = torch.randperm(batch_size, device=x.device)
        mixed_x = lam * x + (1 - lam) * x[index, :]
        y_a, y_b = y, y[index]
        return mixed_x, y_a, y_b, lam

    def cutmix_data(self, x, y):
        if np.random.random() > self.prob:
            return x, y, y, 1.0
        batch_size = x.size(0)
        lam = np.random.beta(self.cutmix_alpha, self.cutmix_alpha)
        index = torch.randperm(batch_size, device=x.device)

        # H, W from (B, C, H, W)
        H, W = x.size(2), x.size(3)
        cut_rat = np.sqrt(1.0 - lam)
        cut_w = int(W * cut_rat)
        cut_h = int(H * cut_rat)

        cx = np.random.randint(W)
        cy = np.random.randint(H)

        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)

        mixed_x = x.clone()
        # Corrected: height dimension first (bby), then width (bbx)
        mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]

        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
        y_a, y_b = y, y[index]
        return mixed_x, y_a, y_b, lam

# ================================================================
# MODEL DEFINITIONS
# ================================================================

def create_resnet50_model(num_classes):
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    for p in model.parameters():
        p.requires_grad = False
    num_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, num_classes)
    )
    for p in model.fc.parameters():
        p.requires_grad = True
    return model

def create_mobilenetv2_model(num_classes):
    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)
    for p in model.parameters():
        p.requires_grad = False
    num_features = model.classifier[1].in_features
    model.classifier = nn.Sequential(
        nn.Dropout(0.2),
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, num_classes)
    )
    for p in model.classifier.parameters():
        p.requires_grad = True
    return model

def create_efficientnet_b0_model(num_classes):
    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)
    for p in model.parameters():
        p.requires_grad = False
    num_features = model.classifier[1].in_features
    model.classifier = nn.Sequential(
        nn.Dropout(0.2),
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, num_classes)
    )
    for p in model.classifier.parameters():
        p.requires_grad = True
    return model

# ================================================================
# MODEL SAVING AND LOADING
# ================================================================

def save_model_metadata(num_classes, class_names, model_info):
    metadata = {
        'num_classes': num_classes,
        'class_names': class_names,
        'model_info': model_info,
        'training_date': time.strftime('%Y-%m-%d %H:%M:%S'),
        'config': {
            'batch_size': Config.BATCH_SIZE,
            'num_epochs': Config.NUM_EPOCHS,
            'learning_rate': Config.LEARNING_RATE,
            'early_stopping_patience': Config.EARLY_STOPPING_PATIENCE
        }
    }
    os.makedirs(os.path.dirname(Config.DRIVE_METADATA_PATH), exist_ok=True)
    with open(Config.DRIVE_METADATA_PATH, 'w') as f:
        json.dump(metadata, f, indent=2)
    print(f"Model metadata saved to: {Config.DRIVE_METADATA_PATH}")

def load_model_metadata():
    if os.path.exists(Config.DRIVE_METADATA_PATH):
        with open(Config.DRIVE_METADATA_PATH, 'r') as f:
            metadata = json.load(f)
        return metadata
    return None

def save_models_to_drive(trained_models, model_results, num_classes, class_names):
    print("Saving models to Google Drive...")
    model_paths = [
        ("ResNet-50", Config.RESNET_PATH, Config.DRIVE_RESNET_PATH),
        ("MobileNetV2", Config.MOBILENET_PATH, Config.DRIVE_MOBILENET_PATH),
        ("EfficientNet-B0", Config.EFFICIENTNET_PATH, Config.DRIVE_EFFICIENTNET_PATH)
    ]
    os.makedirs(os.path.dirname(Config.DRIVE_RESNET_PATH), exist_ok=True)

    model_info = {}
    for model_name, local_path, drive_path in tqdm(model_paths, desc="Saving models", unit="model"):
        if os.path.exists(local_path):
            try:
                shutil.copy2(local_path, drive_path)
                print(f"  {os.path.basename(local_path)} -> Google Drive")
                if model_name in model_results:
                     model_info[model_name] = {
                        'accuracy': model_results[model_name]['accuracy'],
                        'model_path': drive_path
                    }
            except Exception as e:
                print(f"Error saving {local_path} to Google Drive: {e}")
        elif model_name in model_results:
             model_info[model_name] = {
                'accuracy': model_results[model_name]['accuracy'],
                'model_path': drive_path # Record the expected path even if local file not found
            }


    save_model_metadata(num_classes, class_names, model_info)
    print(f"Model metadata saved to: {Config.DRIVE_METADATA_PATH}")


def check_existing_models(num_classes, class_names):
    print("Checking for existing trained models in Google Drive...")
    metadata = load_model_metadata()
    if not metadata:
        print("No model metadata found in Google Drive")
        return False, None
    if (metadata['num_classes'] != num_classes or
        set(metadata['class_names']) != set(class_names)):
        print("Found models but they are incompatible with current classes")
        return False, metadata
    model_paths = [Config.DRIVE_RESNET_PATH, Config.DRIVE_MOBILENET_PATH, Config.DRIVE_EFFICIENTNET_PATH]
    existing_models = {p: os.path.exists(p) for p in model_paths}
    if all(existing_models.values()):
        print("Found all 3 compatible trained models")
        return True, metadata
    print(f"Found {sum(existing_models.values())}/3 models - incomplete set or some files missing")
    return False, metadata

def load_models_from_drive(num_classes, model_names_to_load=None):
    print("Loading trained models from Google Drive...")
    models_config = [
        ("ResNet-50", create_resnet50_model(num_classes), Config.DRIVE_RESNET_PATH),
        ("MobileNetV2", create_mobilenetv2_model(num_classes), Config.DRIVE_MOBILENET_PATH),
        ("EfficientNet-B0", create_efficientnet_b0_model(num_classes), Config.DRIVE_EFFICIENTNET_PATH)
    ]
    loaded_models = {}
    for model_name, model, drive_path in tqdm(models_config, desc="Loading models", unit="model"):
        if model_names_to_load is None or model_name in model_names_to_load:
            try:
                if os.path.exists(drive_path):
                    model.load_state_dict(torch.load(drive_path, map_location=Config.DEVICE))
                    model = model.to(Config.DEVICE)
                    loaded_models[model_name] = model
                    print(f"  {model_name} loaded successfully")
                else:
                    print(f"  Model file not found for {model_name} at {drive_path}")
            except Exception as e:
                print(f"  Error loading {model_name} from {drive_path}: {e}")
                # If loading fails for a specific model, we can still try to load others
                loaded_models[model_name] = None # Indicate failure to load this model
    if len(loaded_models) == 0 or any(m is None for m in loaded_models.values()) and model_names_to_load is None:
         print("Could not load all specified models from Google Drive.")
         # Return None if we intended to load all but failed for some
         return None
    print("Finished attempting to load specified models from Google Drive")
    return loaded_models

def ask_user_preference():
    print("What would you like to do?")
    print("1) Use existing trained models (fast)")
    print("2) Retrain all models (slow)")
    print("3) Retrain and overwrite existing models")
    print("4) Continue training MobileNetV2 and EfficientNet-B0") # New option
    try:
        choice = input("Enter your choice (1, 2, 3, or 4): ").strip()
        if choice in ['1', '2', '3', '4']:
            return int(choice)
        else:
            print("Invalid choice. Defaulting to 1")
            return 1
    except Exception:
        print("Input failed. Defaulting to 1")
        return 1

# ================================================================
# TRAINING / EVAL (with MixUp/CutMix)
# ================================================================

def mixup_cutmix_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

def compute_class_weights(loader, num_classes):
    counts = torch.zeros(num_classes, dtype=torch.long)
    # Ensure we iterate through the entire dataset if it's not already iterated
    dataset = loader.dataset
    # Accessing dataset directly is usually safe for counting
    for _, labels in dataset:
        counts[labels] += 1
    weights = counts.float().sum() / (num_classes * counts.clamp(min=1).float())
    return weights

def train_model(model, train_loader, val_loader, model_name, save_path, num_epochs, use_mixup_cutmix=True, start_epoch=0, history=None):
    model = model.to(Config.DEVICE)

    # Optional class weights if imbalance
    class_weights = compute_class_weights(train_loader, num_classes=len(train_loader.dataset.classes))
    class_weights = class_weights.to(Config.DEVICE)

    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)
    # Adjust scheduler start based on start_epoch
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
    # If resuming, step the scheduler to the correct state
    for _ in range(start_epoch):
        scheduler.step()


    # MixUp/CutMix helper
    mcm = MixUpCutMix(mixup_alpha=0.2, cutmix_alpha=1.0, prob=0.5) if use_mixup_cutmix else None

    best_val_acc = 0.0
    best_val_loss = float('inf')
    best_model_wts = copy.deepcopy(model.state_dict())
    epochs_without_improvement = 0
    early_stopped = False

    # Initialize or continue history
    if history is None:
        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    else:
         # If resuming, find the best validation loss/accuracy from existing history
         if history['val_loss']:
             best_val_loss = min(history['val_loss'])
         if history['val_acc']:
             best_val_acc = max(history['val_acc'])
         print(f"Resuming training for {model_name} from epoch {start_epoch+1}")
         print(f"Initial best validation loss: {best_val_loss:.4f}, accuracy: {best_val_acc:.4f}")


    print(f"Training {model_name}")
    print(f"Early stopping patience: {Config.EARLY_STOPPING_PATIENCE} epochs")
    print("Using MixUp/CutMix" if use_mixup_cutmix else "Standard training")
    print("=" * 50)

    for epoch in tqdm(range(start_epoch, num_epochs), desc=f"Training {model_name}", unit="epoch", initial=start_epoch, total=num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")

        model.train()
        running_loss = 0.0
        running_corrects = 0.0
        total_samples = 0

        # Use enumerate for progress bar with known length
        for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f"Training Epoch {epoch+1}", leave=False, unit="batch")):
            inputs = inputs.to(Config.DEVICE, non_blocking=True)
            labels = labels.to(Config.DEVICE, non_blocking=True)

            optimizer.zero_grad()

            if mcm and np.random.random() < 0.5:
                # MixUp or CutMix randomly
                if np.random.random() < 0.5:
                    inputs_mixed, labels_a, labels_b, lam = mcm.mixup_data(inputs, labels)
                else:
                    inputs_mixed, labels_a, labels_b, lam = mcm.cutmix_data(inputs, labels)
                outputs = model(inputs_mixed)
                loss = mixup_cutmix_criterion(criterion, outputs, labels_a, labels_b, lam)
                # Calculate corrects based on lambda weights
                with torch.no_grad():
                    _, preds = torch.max(outputs, 1)
                    corrects = lam * torch.sum(preds == labels_a).float() + (1 - lam) * torch.sum(preds == labels_b).float()

            else:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                _, preds = torch.max(outputs, 1)
                corrects = torch.sum(preds == labels.data).float()

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            batch_size = inputs.size(0)
            running_loss += loss.item() * batch_size
            running_corrects += corrects.item() # Use .item() to get scalar
            total_samples += batch_size

        # Validation
        model.eval()
        val_running_loss = 0.0
        val_running_corrects = 0

        with torch.no_grad():
            # Use enumerate for progress bar with known length
            for i, (inputs, labels) in enumerate(tqdm(val_loader, desc=f"Validation Epoch {epoch+1}", leave=False, unit="batch")):
                inputs = inputs.to(Config.DEVICE, non_blocking=True)
                labels = labels.to(Config.DEVICE, non_blocking=True)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                _, preds = torch.max(outputs, 1)
                val_running_loss += loss.item() * inputs.size(0)
                val_running_corrects += torch.sum(preds == labels.data).item() # Use .item()

        epoch_train_loss = running_loss / max(total_samples, 1)
        epoch_train_acc = running_corrects / max(total_samples, 1)
        epoch_val_loss = val_running_loss / len(val_loader.dataset)
        epoch_val_acc = val_running_corrects / len(val_loader.dataset)

        history['train_loss'].append(epoch_train_loss)
        history['train_acc'].append(epoch_train_acc)
        history['val_loss'].append(epoch_val_loss)
        history['val_acc'].append(epoch_val_acc)

        print(f"Train Loss: {epoch_train_loss:.4f} | Acc: {epoch_train_acc:.4f}")
        print(f"Val   Loss: {epoch_val_loss:.4f} | Acc: {epoch_val_acc:.4f}")

        improved = False
        # Use current validation accuracy for early stopping check
        if epoch_val_loss < (best_val_loss - Config.MIN_DELTA):
            best_val_loss = epoch_val_loss
            epochs_without_improvement = 0 # Reset counter on loss improvement
            improved = True
            print(f"Validation loss improved: {epoch_val_loss:.4f}")
        else:
             epochs_without_improvement += 1
             print(f"No validation loss improvement for {epochs_without_improvement}/{Config.EARLY_STOPPING_PATIENCE} epochs")


        if epoch_val_acc > best_val_acc:
            best_val_acc = epoch_val_acc
            best_model_wts = copy.deepcopy(model.state_dict())
            print(f"New best validation accuracy: {best_val_acc:.4f}")
             # Do not reset epochs_without_improvement based on accuracy alone for loss-based patience

        if epochs_without_improvement >= Config.EARLY_STOPPING_PATIENCE:
            print(f"Early stopping triggered after {epoch + 1} epochs")
            early_stopped = True
            break


        scheduler.step()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    model.load_state_dict(best_model_wts)
    torch.save(model.state_dict(), save_path)

    final_epoch = epoch + 1 if early_stopped else num_epochs
    print(f"Saved best model to: {save_path}")
    print(f"Final best validation accuracy: {best_val_acc:.4f}")
    print(f"Training completed in {final_epoch} epochs")

    return model, history

# ================================================================
# EVALUATION / ENSEMBLE
# ================================================================

def evaluate_model(model, test_loader):
    model.eval()
    all_preds, all_labels, all_probs = [], [], []
    with torch.no_grad():
        for inputs, labels in tqdm(test_loader, desc="Evaluating", unit="batch"):
            inputs = inputs.to(Config.DEVICE, non_blocking=True)
            labels = labels.to(Config.DEVICE, non_blocking=True)
            outputs = model(inputs)
            probabilities = torch.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probabilities.cpu().numpy())
    accuracy = accuracy_score(all_labels, all_preds)
    return accuracy, all_preds, all_labels, np.array(all_probs)

def ensemble_predict(models_list, test_loader):
    print("Performing ensemble prediction...")
    all_model_probs = []
    labels = []
    # Collect labels only once
    for i, (x, y) in enumerate(test_loader):
        if i == 0:
            labels = y.numpy()  # grab all labels
        else:
            labels = np.concatenate([labels, y.numpy()])

    # Now collect predictions from each model
    for m in models_list:
        if m is None:
            continue
        m.eval()
        probs_collect = []
        with torch.no_grad():
            for x, _ in test_loader:
                x = x.to(Config.DEVICE, non_blocking=True)
                p = torch.softmax(m(x), dim=1).cpu().numpy()
                probs_collect.extend(p)
        all_model_probs.append(np.array(probs_collect))

    if not all_model_probs:
        return 0.0, [], [], []

    # Average predictions
    ensemble_probs = np.mean(all_model_probs, axis=0)
    preds = np.argmax(ensemble_probs, axis=1)

    acc = accuracy_score(labels, preds)
    return acc, preds, labels, ensemble_probs

# ================================================================
# VISUALIZATION
# ================================================================

def plot_training_history(history, model_name):
    epochs = range(1, len(history['train_loss']) + 1)

    plt.figure(figsize=(12,5))

    # Loss curves
    plt.subplot(1,2,1)
    plt.plot(epochs, history['train_loss'], label="Train Loss")
    plt.plot(epochs, history['val_loss'], label="Val Loss")
    plt.title(f"{model_name} Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)

    # Accuracy curves
    plt.subplot(1,2,2)
    plt.plot(epochs, history['train_acc'], label="Train Acc")
    plt.plot(epochs, history['val_acc'], label="Val Acc")
    plt.title(f"{model_name} Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(y_true, y_pred, class_names, title="Confusion Matrix"):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(15, 12))
    im = plt.imshow(cm, cmap='Blues')
    plt.colorbar(im)
    plt.title(title, fontsize=16)
    plt.ylabel('True Label'); plt.xlabel('Predicted Label')
    plt.xticks(ticks=np.arange(len(class_names)), labels=class_names, rotation=45, ha='right')
    plt.yticks(ticks=np.arange(len(class_names)), labels=class_names)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, cm[i, j], ha='center', va='center', color='black')
    plt.tight_layout(); plt.show()

def plot_model_comparison(model_results, ensemble_accuracy):
    models_n = list(model_results.keys()) + ['Ensemble']
    accuracies = [results['accuracy'] for results in model_results.values()] + [ensemble_accuracy]
    plt.figure(figsize=(10, 6))
    bars = plt.bar(models_n, accuracies)
    for bar, acc in zip(bars, accuracies):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{acc:.3f}', ha='center', va='bottom')
    plt.title('Model Performance Comparison', fontsize=16)
    plt.ylabel('Accuracy'); plt.ylim(0, 1); plt.grid(axis='y', alpha=0.3)
    plt.tight_layout(); plt.show()

# ================================================================
# ENHANCED MAIN FUNCTION WITH NEW FEATURES
# ================================================================

def main_enhanced():
    """Enhanced main function using regularization and advanced augmentation"""
    print("Enhanced Medicinal Leaf Classification - 3 Models + Ensemble")
    print("Features: L1/L2 Regularization + Advanced Data Augmentation")
    print("=" * 60)

    # Call setup_dataset here before creating data loaders
    if not setup_dataset():
        print("Dataset setup failed. Please check your data structure.")
        return None, None, None

    # Data loading is now done inside this function
    # Use enhanced augmentation
    train_tf, val_tf = create_enhanced_transforms()

    print("Loading enhanced datasets with advanced augmentation...")
    train_dataset = datasets.ImageFolder(root=Config.TRAIN_DIR, transform=train_tf)
    val_dataset = datasets.ImageFolder(root=Config.VAL_DIR, transform=val_tf)
    test_dataset = datasets.ImageFolder(root=Config.TEST_DIR, transform=val_tf)

    num_classes = len(train_dataset.classes)
    class_names = train_dataset.classes

    print("Enhanced dataset loaded successfully")
    print(f"Classes: {num_classes}")
    print(f"Train: {len(train_dataset)} images")
    print(f"Val: {len(val_dataset)} images")
    print(f"Test: {len(test_dataset)} images")

    train_loader = DataLoader(
        train_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=True,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY,
        persistent_workers=True if Config.NUM_WORKERS > 0 else False
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY,
        persistent_workers=True if Config.NUM_WORKERS > 0 else False
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY,
        persistent_workers=True if Config.NUM_WORKERS > 0 else False
    )

    has_existing_models, metadata = check_existing_models(num_classes, class_names)

    trained_models = {} # Use dictionary for easier access by name
    model_results = {}
    training_histories = []

    choice = 1
    if has_existing_models:
        choice = ask_user_preference()
        if choice == 1:
            loaded_models = load_models_from_drive(num_classes)
            if loaded_models:
                trained_models = loaded_models
                print("Using existing trained models.")
                # Evaluate loaded models to get results
                print("\nEvaluating loaded models on test set...")
                for name, model in trained_models.items():
                    if model is not None: # Check if model loaded successfully
                        test_accuracy, test_preds, test_labels, test_probs = evaluate_model(model, test_loader)
                        print(f"{name} Test Accuracy: {test_accuracy:.4f}")
                        model_results[name] = {
                            'accuracy': test_accuracy,
                            'predictions': test_preds,
                            'probabilities': test_probs
                        }
                    else:
                         print(f"Skipping evaluation for {name} as it failed to load.")
                # Load historical metadata for plotting/saving if available
                if metadata and 'model_info' in metadata:
                     for name, info in metadata['model_info'].items():
                         if name not in model_results:
                             model_results[name] = {'accuracy': info.get('accuracy', 0.0)} # Add placeholder if not evaluated
                # No training history to plot in this case
            else:
                print("Failed to load models. Starting fresh training...")
                choice = 2 # Fallback to retraining all

    models_config = [
        ("MobileNetV2", create_mobilenetv2_model(num_classes), Config.MOBILENET_PATH, Config.DRIVE_MOBILENET_PATH),
        ("EfficientNet-B0", create_efficientnet_b0_model(num_classes), Config.EFFICIENTNET_PATH, Config.DRIVE_EFFICIENTNET_PATH),
        ("ResNet-50", create_resnet50_model(num_classes), Config.RESNET_PATH, Config.DRIVE_RESNET_PATH)
    ]

    if choice in [2, 3, 4]: # Retrain All, Overwrite, or Continue Training
        models_to_train = []
        if choice == 4: # Continue training specific models
            print("\nContinuing training for MobileNetV2 and EfficientNet-B0...")
            models_to_continue = ["MobileNetV2", "EfficientNet-B0"]
            # Attempt to load existing models to continue training from
            loaded_models_for_resume = load_models_from_drive(num_classes, model_names_to_load=models_to_continue)
            if loaded_models_for_resume:
                for model_name, model, save_path, drive_path in models_config:
                    if model_name in models_to_continue:
                        if model_name in loaded_models_for_resume and loaded_models_for_resume[model_name] is not None:
                             print(f"Loaded {model_name} from Drive to continue training.")
                             models_to_train.append((model_name, loaded_models_for_resume[model_name], save_path, drive_path))
                        else:
                             print(f"Could not load {model_name} from Drive, starting fresh training.")
                             models_to_train.append((model_name, create_mobilenetv2_model(num_classes) if model_name == "MobileNetV2" else create_efficientnet_b0_model(num_classes), save_path, drive_path))
                # For choice 4, we still need the ResNet-50 model for the ensemble if it exists
                if "ResNet-50" not in trained_models:
                     resnet_model = load_models_from_drive(num_classes, model_names_to_load=["ResNet-50"])
                     if resnet_model and resnet_model.get("ResNet-50") is not None:
                         trained_models["ResNet-50"] = resnet_model["ResNet-50"]
                         print("Loaded ResNet-50 for ensembling.")
            else:
                 print("Failed to load specified models for continuing training. Starting fresh training for them.")
                 for model_name, model, save_path, drive_path in models_config:
                      if model_name in models_to_continue:
                           models_to_train.append((model_name, create_mobilenetv2_model(num_classes) if model_name == "MobileNetV2" else create_efficientnet_b0_model(num_classes), save_path, drive_path))
                 # Still need ResNet-50 if available
                 if "ResNet-50" not in trained_models:
                     resnet_model = load_models_from_drive(num_classes, model_names_to_load=["ResNet-50"])
                     if resnet_model and resnet_model.get("ResNet-50") is not None:
                         trained_models["ResNet-50"] = resnet_model["ResNet-50"]
                         print("Loaded ResNet-50 for ensembling.")


        else: # Retrain All or Overwrite
            models_to_train = models_config
            # Clear trained_models dictionary if retraining all
            trained_models = {}

        for model_name, model, save_path, drive_path in models_to_train:
            print("\n" + '='*60)
            start_epoch = 0
            history = None
            # If continuing training (choice 4) or overwriting (choice 3) and model was partially trained, load state
            if choice in [3, 4] and model_name in trained_models and trained_models[model_name] is not None:
                 print(f"Attempting to continue training for {model_name}...")
                 # We already loaded the state if it existed for choice 4.
                 # For choice 3 (overwrite), we just use the potentially loaded model or a fresh one.
                 # History is not automatically loaded; we start fresh for history plotting unless we implement history loading.
                 # For simplicity in this modification, we will not load previous history for plotting,
                 # but the model state is loaded for continued training.


            trained_model, current_history = train_model(
                model, train_loader, val_loader, model_name, save_path, Config.NUM_EPOCHS, use_mixup_cutmix=True, start_epoch=start_epoch, history=history
            )
            training_histories.append(current_history)

            # ðŸ“Š Plot training history after each model
            plot_training_history(current_history, model_name)


            print(f"\nEvaluating {model_name} on test set...")
            test_accuracy, test_preds, test_labels, test_probs = evaluate_model(trained_model, test_loader)
            print(f"{model_name} Test Accuracy: {test_accuracy:.4f}")

            trained_models[model_name] = trained_model # Add the trained model to the dictionary
            model_results[model_name] = {
                'accuracy': test_accuracy,
                'predictions': test_preds,
                'probabilities': test_probs
            }

    # Ensure all necessary models are in trained_models for ensembling, loading others if needed
    required_models = ["ResNet-50", "MobileNetV2", "EfficientNet-B0"]
    for req_model_name in required_models:
        if req_model_name not in trained_models or trained_models[req_model_name] is None:
            print(f"Attempting to load {req_model_name} from Drive for ensembling...")
            loaded_m = load_models_from_drive(num_classes, model_names_to_load=[req_model_name])
            if loaded_m and loaded_m.get(req_model_name) is not None:
                trained_models[req_model_name] = loaded_m[req_model_name]
                print(f"Successfully loaded {req_model_name} for ensembling.")
                 # If a required model was just loaded, evaluate it to include in results
                if req_model_name not in model_results:
                     print(f"Evaluating newly loaded {req_model_name} on test set...")
                     test_accuracy, test_preds, test_labels, test_probs = evaluate_model(trained_models[req_model_name], test_loader)
                     print(f"{req_model_name} Test Accuracy: {test_accuracy:.4f}")
                     model_results[req_model_name] = {
                         'accuracy': test_accuracy,
                         'predictions': test_preds,
                         'probabilities': test_probs
                     }
            else:
                print(f"Could not load {req_model_name}. Ensemble performance may be affected.")
                trained_models[req_model_name] = None # Explicitly mark as None if loading failed

    # Save the state of all models that were trained or loaded
    all_trained_or_loaded_models = [m for m in trained_models.values() if m is not None]
    # We need to save the state_dict of the models that were trained/continued or loaded.
    # The save_models_to_drive function saves from the local paths, which are updated after training.
    # We should update model_results with evaluation results before saving metadata.
    save_models_to_drive(all_trained_or_loaded_models, model_results, num_classes, class_names)


    # if training_histories:
    #     print("\nTraining History Visualization:")
    #     # Pass the names of models that were actually trained/resumed
    #     trained_model_names = [name for name, model, _, _ in models_to_train]
    #     plot_training_history(training_histories, trained_model_names)


    print("\n" + "="*60)
    print("INDIVIDUAL MODEL RESULTS")
    print("="*60)
    for model_name, results in model_results.items():
         print(f"{model_name}: {results['accuracy']:.4f}")


    print("\n" + "="*60)
    print("ENSEMBLE PREDICTION")
    print("="*60)

    # Pass only successfully loaded/trained models to ensemble_predict
    successfully_loaded_models_list = [model for model in trained_models.values() if model is not None]

    if successfully_loaded_models_list:
        ensemble_accuracy, ensemble_preds, true_labels, ensemble_probs = ensemble_predict(
            successfully_loaded_models_list, test_loader
        )

        print(f"Ensemble Accuracy: {ensemble_accuracy:.4f}")

        print("\nPerformance Comparison:")
        plot_model_comparison(model_results, ensemble_accuracy)

        print("\nEnsemble Confusion Matrix:")
        plot_confusion_matrix(true_labels, ensemble_preds, class_names, "Ensemble Confusion Matrix")

        print("\nClassification Report:")
        print("-" * 50)
        report = classification_report(true_labels, ensemble_preds, target_names=class_names, digits=4)
        print(report)

        print("\n" + "="*60)
        print("FINAL RESULTS SUMMARY")
        print("="*60)
        for model_name, results in model_results.items():
            print(f"{model_name}: {results['accuracy']:.4f}")
        print(f"Ensemble: {ensemble_accuracy:.4f}")

        results_df = pd.DataFrame([
            {'Model': name, 'Accuracy': results['accuracy']}
            for name, results in model_results.items()
        ] + [{'Model': 'Ensemble', 'Accuracy': ensemble_accuracy}])
        results_df.to_csv('model_comparison_results.csv', index=False)
        print("Results saved to: model_comparison_results.csv")

        # Also save into Drive so it overwrites the old file
        drive_results_path = "/content/drive/MyDrive/medicinal/model_comparison_results.csv"
        shutil.copy2("model_comparison_results.csv", drive_results_path)
        print(f"ðŸ”— Results CSV saved to Google Drive: {drive_results_path}")

        return trained_models, model_results, ensemble_accuracy
    else:
        print("No models were successfully loaded or trained. Cannot perform ensembling or report final results.")
        return None, model_results, 0.0

# ================================================================
# RUN THE PIPELINE
# ================================================================

if __name__ == "__main__":
    torch.manual_seed(42)
    np.random.seed(42)
    result = main_enhanced() # Call the enhanced main function
    if result and result[0] is not None:
        trained_models, model_results, ensemble_accuracy = result
        print("Training and evaluation completed successfully")
    else:
        print("Pipeline execution finished, but not all models were successfully trained/loaded.")

import os
import matplotlib.pyplot as plt

# Paths to your train, val, test folders
train_dir = "/content/data/train"
val_dir = "/content/data/val"
test_dir = "/content/data/test"

# Function to count images per class
def count_images_per_class(folder):
    class_counts = {}
    for cls in sorted(os.listdir(folder)):
        cls_path = os.path.join(folder, cls)
        if os.path.isdir(cls_path):
            class_counts[cls] = len(os.listdir(cls_path))
    return class_counts

# Count images for each split
train_counts = count_images_per_class(train_dir)
val_counts = count_images_per_class(val_dir)
test_counts = count_images_per_class(test_dir)

# Plot dataset distribution for training set (you can repeat for val/test)
plt.figure(figsize=(20, 6))
plt.bar(train_counts.keys(), train_counts.values(), color="skyblue")
plt.xticks(rotation=90, fontsize=8)
plt.title("Dataset Distribution per Class (Train Set)")
plt.xlabel("Classes")
plt.ylabel("Number of Images")
plt.tight_layout()
plt.show()

import pandas as pd
import os
# Convert counts into pandas DataFrame
df = pd.DataFrame({
    "Class": list(train_counts.keys()),
    "Train": list(train_counts.values()),
    "Validation": [val_counts.get(cls, 0) for cls in train_counts.keys()],
    "Test": [test_counts.get(cls, 0) for cls in train_counts.keys()]
})

# Add totals row
totals = pd.DataFrame([{
    "Class": "TOTAL",
    "Train": df["Train"].sum(),
    "Validation": df["Validation"].sum(),
    "Test": df["Test"].sum()
}])

df = pd.concat([df, totals], ignore_index=True)

# Display the table
# import caas_jupyter_tools
# caas_jupyter_tools.display_dataframe_to_user("Dataset Split Summary", df)
display(df)


# Save to CSV if needed
df.to_csv("/content/dataset_split_summary.csv", index=False)
print("Saved summary to /content/dataset_split_summary.csv")

import os
import random
import matplotlib.pyplot as plt
from PIL import Image
import torchvision.transforms as transforms

# Path to your train dataset
train_dir = "/content/data/train"

# Define preprocessing & augmentation pipeline
preprocess_augment = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.RandomRotation(degrees=25),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization
                         std=[0.229, 0.224, 0.225])
])

# Pick a random class and random image
random_class = random.choice(os.listdir(train_dir))
class_path = os.path.join(train_dir, random_class)
img_name = random.choice(os.listdir(class_path))
img_path = os.path.join(class_path, img_name)

img = Image.open(img_path).convert("RGB")

# Show original + 5 augmented versions
plt.figure(figsize=(15, 3))

# Original
plt.subplot(1, 6, 1)
plt.imshow(img)
plt.title("Original", fontsize=10)
plt.axis("off")

# Augmented versions
for i in range(5):
    aug_img = preprocess_augment(img)
    aug_vis = aug_img.permute(1, 2, 0).numpy()
    aug_vis = (aug_vis - aug_vis.min()) / (aug_vis.max() - aug_vis.min())  # Rescale for display

    plt.subplot(1, 6, i+2)
    plt.imshow(aug_vis)
    plt.title(f"Augmented {i+1}", fontsize=10)
    plt.axis("off")

plt.suptitle(f"Preprocessing & Augmentation Examples â€“ Class: {random_class}", fontsize=14)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Paste your classification report text here (trimmed for brevity, include full in Colab)
report_text = """
               precision    recall  f1-score   support

    Aloevera     0.9565    0.9167    0.9362        24
        Amla     0.7692    0.7143    0.7407        14
 Amruthaballi     0.8462    0.5789    0.6875        19
       Arali     0.9000    1.0000    0.9474        18
  Astma_weed     0.7647    0.7647    0.7647        17
     Badipala     0.7333    0.6875    0.7097        16
 Balloon_Vine     1.0000    0.9231    0.9600        13
...
               accuracy                         0.8239      1414
              macro avg     0.8352    0.8373    0.8272      1414
           weighted avg     0.8407    0.8239    0.8212      1414
"""

# Parse classification report into DataFrame
lines = report_text.strip().split("\n")
rows = []
for line in lines[2:]:  # skip header
    parts = line.split()
    if len(parts) >= 5:
        cls = " ".join(parts[:-4])
        precision, recall, f1, support = parts[-4:]
        rows.append([cls, float(precision), float(recall), float(f1), int(support)])

df = pd.DataFrame(rows, columns=["Class", "Precision", "Recall", "F1-score", "Support"])

# Plot Precision, Recall, F1-score as separate bar charts
fig, ax = plt.subplots(3, 1, figsize=(20, 18), sharex=True)

# Precision
df.plot(x="Class", y="Precision", kind="bar", ax=ax[0], color="skyblue", legend=False)
ax[0].set_title("Precision per Class (Ensemble Model)", fontsize=14, fontweight="bold")
ax[0].set_ylabel("Precision", fontsize=12)
ax[0].set_xlabel("")  # Hide x-axis label (shown only at bottom)
ax[0].set_ylim(0, 1.1)
ax[0].grid(axis="y", linestyle="--", alpha=0.7)

# Recall
df.plot(x="Class", y="Recall", kind="bar", ax=ax[1], color="lightgreen", legend=False)
ax[1].set_title("Recall per Class (Ensemble Model)", fontsize=14, fontweight="bold")
ax[1].set_ylabel("Recall", fontsize=12)
ax[1].set_xlabel("")
ax[1].set_ylim(0, 1.1)
ax[1].grid(axis="y", linestyle="--", alpha=0.7)

# F1-score
df.plot(x="Class", y="F1-score", kind="bar", ax=ax[2], color="salmon", legend=False)
ax[2].set_title("F1-score per Class (Ensemble Model)", fontsize=14, fontweight="bold")
ax[2].set_ylabel("F1-score", fontsize=12)
ax[2].set_xlabel("Classes", fontsize=12)
ax[2].set_ylim(0, 1.1)
ax[2].grid(axis="y", linestyle="--", alpha=0.7)

plt.xticks(rotation=90, fontsize=8)
plt.tight_layout()
plt.show()